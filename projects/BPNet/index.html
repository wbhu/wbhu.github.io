<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>BPNet</title>
</head>

<body>
<center>
    <table border="0" width="920" id="table1" height="568">
        <tr>
            <td colspan="2" width="864" height="22">
                <b>
                    <font FACE="Tahoma" size="4" color="#666666">
                        <i>CVPR </i>
                    </font>
                    <font face="Tahoma" size="4" color="#C0C0C0">
                        <i>2021</i>
                    </font>
                    <font color="#666666" face="Tahoma" size="4">
                        <i>(Oral)</i>
                    </font>
                </b>
            </td>
        </tr>
        <tr>
            <td colspan="2" width="864" height="78">
                <p style="margin-top: 13px; margin-bottom: 13px" align="center">
                    <font FACE="Tahoma" style="font-size: 32pt; font-weight: 700">Bidirectional Projection Network <br>
                        for Cross Dimension Scene Understanding</font>
            </td>
        </tr>
        <tr>
            <td colspan="2" width="864" height="19">
                <p align="center">
                    <font face="Arial">
                        <b>
                            <a href="https://wbhu.github.io/">Wenbo Hu</a>*
                            <font size="2"><sup>1,3</sup></font>
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            <a href="https://hszhao.github.io/">Hengshuang Zhao</a>*
                            <font size="2"><sup>2</sup></font>
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            <a href="https://scholar.google.com/citations?user=5cIodxsAAAAJ&hl=en">Li Jiang</a>
                            <font size="2"><sup>1</sup></font>
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            <a href="http://jiaya.me/">Jiaya Jia</a>
                            <font size="2"><sup>1</sup></font>
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
                            <font size="2"><sup>† 1,3</sup></font>
                            <br><br>
                            <small>(* Joint 1st authors;&nbsp; † The corresponding author.)</small>
                        </b>
                    </font>
                </p>
            </td>
        </tr>

        <tr>
            <td>
                <p align="center">
                    <img border="0" src="img/logo.jpg" style="width:100%">
                </p>
            </td>
        </tr>

        <tr>
            <td>&nbsp;</td>
        </tr>
        <tr>
            <td>&nbsp;</td>
        </tr>
        <!--        <tr><td>&nbsp;</td></tr>-->

        <tr>
            <td width="924" height="314" colspan="">
                <!--                <p align="center">-->
                <p align="justify">
                    <img border="0" src="img/bpnet.jpg" style="width:100%">
                    <br><br>
                    <font face="Cambria" color="#505050">
                        2D image representations are in regular grids and can be processed efficiently, whereas 3D point
                        clouds are unordered and scattered in 3D space. The information inside these two visual domains
                        is well complementary, e.g., 2D images have fine-grained texture while 3D point clouds contain
                        plentiful geometry information. However, most current visual recognition systems process them
                        individually. In this paper, we present a bidirectional projection network (BPNet) for joint 2D
                        and 3D reasoning in an end-to-end manner. It contains 2D and 3D sub-networks with symmetric
                        architectures, that are connected by our proposed bidirectional projection module (BPM). Via
                        the BPM, complementary 2D and 3D information can interact with each other in multiple
                        architectural levels, such that advantages in these two visual domains can be combined for
                        better scene recognition. Extensive quantitative and qualitative experimental evaluations show
                        that joint reasoning over 2D and 3D visual domains can benefit both 2D and 3D scene
                        understanding simultaneously. Our BPNet achieves top performance on the ScanNetV2 benchmark
                        for both 2D and 3D semantic segmentation (Benchmark: <a
                            href="http://kaldir.vc.in.tum.de/scannet_benchmark/semantic_label_3d">3D</a> / <a
                            href="http://kaldir.vc.in.tum.de/scannet_benchmark/semantic_label_2d">2D</a>).
                    </font>
                </p>
            </td>
        </tr>

    </table>

    <br>
    <table width="935" height="400">
        <tr>
            <td width="43" height="400" rowspan="3"></td>
            <td width="552" height="400" rowspan="3">
                <font FACE="Arial" style="font-weight: normal">
                    <p align="left"><b><font size="5" face="Arial">
                        Video</font></b></p>
                    <p align="justify"><font face="Arial">
                        <iframe width="640" height="360" src="https://www.youtube.com/embed/Wt9J1l_UBaA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        
                    </font></p>
                </font>
            </td>

            <td width="13" height="400" rowspan="3"></td>
            <td width="105" height="105">
                <p align="center">
                    <a href="https://arxiv.org/abs/2103.14326">
                        <img border="1" src="img/thumb_paper.jpg" style="width:80%"></a>
            </td>
            <td height="105">
                <p style="margin-top: 0; margin-bottom: 0"><font face="Arial"><b>Paper</b></font></p>
                <p style="margin-top: 0; margin-bottom: 0"><font face="Arial">(PDF, 26.8MB)</font></p>
            </td>
        </tr>

        <tr>
            <td width="105" height="105">
                <p align="center">
                    <a href="https://github.com/wbhu/BPNet">
                        <img border="1" src="img/thumb_github.png" style="width:80%"></a>
            </td>
            <td height="105">
                <p style="margin-top: 0; margin-bottom: 0"><font face="Arial"><b>Source Code</b></font></p>
<!--                <p style="margin-top: 0; margin-bottom: 0"><font face="Arial">(To be released)</font></p>-->
            </td>
        </tr>
    </table>


    <table width="935" height="200">
        <tr>
            <td width="552" align="left">
                <font FACE="Arial">
                    <p align="left"><b>BibTex:</b></p>

                    <p align="left"><font face="Courier New" size="2" color="#666666">
                    <pre>
    @inproceedings{hu-2021-bidirectional,
        author      = {Wenbo Hu, Hengshuang Zhao, Li Jiang, Jiaya Jia and Tien-Tsin Wong},
        title       = {Bidirectional Projection Network for Cross Dimensional Scene Understanding},
        booktitle   = {CVPR},
        year        = {2021}
    }
</pre>
                    </p>
            </td>
        </tr>
    </table>

</center>
</body>
</html>
